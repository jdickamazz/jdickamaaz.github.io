<html>
<head>
<link rel="stylesheet" href="style.css">

<link href="https://fonts.googleapis.com/css?family=PT+Serif|Merriweather|Oswald|Ubuntu+Mono" rel="stylesheet">
<title>Michael Saxon - Publications</title>
<script src="resize.js">
</script>

</head>
<!--body class="sba" onload="resizeleft()" onresize="resizeleft()"-->
<body>


  <!--div class="header"><h1>&nbsp;</h1></div-->



  <header style="border-top:2px solid black; border-bottom: 1px dotted #676767; position:relative; min-height: 60px; overflow:hidden;">
    <!--div class="menucontainer" -->
    <div class="page">
    <h2 style="margin-top:6pt;float:left;"><a class="active" href="/">Michael Saxon</a></h2>
    <ul class="menu" style="margin-top:10pt;">
    <!--li><a href="projects.html">Projects</a></li-->
    <!--li><a href="/">About</a></li-->
    <li><a href="research">Publications</a></li>
    <!--li><a href="fun">Fun</a></li-->
      <li><a href="doc/cv_saxon.pdf">CV</a></li>
      <li><a href="blog/">Blog</a></li>
    </ul>
  </div>
  </header>


  <div class="page" id="rightcontent" style="padding-top:15pt; overflow: hidden;">

<h3 >Conference, Journal, Preprint</h3><br>

<h4>2023</h4>

<p style="padding-bottom: 10pt;"><b style="font-size:13pt;"><span class="tomato">New!</span> Let's Think Frame by Frame with VIP: A Video Infilling and Prediction Dataset for Evaluating Video Chain-of-Thought </b><br>
Vaishnavi Himakunthala*, Andy Ouyang*, Daniel Rose*, Ryan He*, Alex Mei, Yujie Lu, Chinmay Sonar, <u>Michael Saxon</u>, William Yang Wang<br>
<i><b>EMNLP 2023</b></i> <br>
<a href="https://arxiv.org/abs/2305.13903">arXiv:2305.13903</a> <a href="https://arxiv.org/pdf/2305.13903">[pdf]</a></p>


<p style="padding-bottom: 10pt;"><b style="font-size:13pt;"><span class="tomato">New!</span> Large Language Models Are Implicitly Topic Models: Explaining and Finding Good Demonstrations for In-Context Learning</b><br>
  Xinyi Wang, Wanrong Zhu, <u>Michael Saxon</u>, Mark Steyvers, William Yang Wang<br>
  <i><b>NeurIPS 2023</b></i> <br>
  <a href="https://arxiv.org/abs/2301.11916">arXiv:2301.11916</a> <a href="https://arxiv.org/pdf/2301.11916">[pdf]</a></p>  

<p style="padding-bottom: 10pt;"><b style="font-size:13pt;"><span class="tomato">New!</span>  Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies </b><br>
 Liangming Pan, <u>Michael Saxon</u>, Wenda Xu, Deepak Nathani, Xinyi Wang, William Yang Wang
<i>preprint</i> <br>
<a href="https://arxiv.org/abs/2308.03188">arxiv:2308.03188</a> <a href="https://arxiv.org/pdf/2308.03188.pdf">[pdf]</a> </p>


<p style="padding-bottom: 10pt;"><b style="font-size:13pt;"><span class="tomato">New!</span> Multilingual Conceptual Coverage in Text-to-Image Models</b><br>
<u>Michael Saxon</u>, William Yang Wang<br>
<i><b>ACL 2023</b></i> <br>
<a href="https://arxiv.org/abs/2306.01735">arxiv:2306.01735</a> <a href="https://arxiv.org/pdf/2306.01735.pdf">[pdf]</a> <a href="coco-crola/">[demo]</a></p>

<p style="padding-bottom: 10pt;"><b style="font-size:13pt;"> CausalDialogue: Modeling Utterance-level Causality in Conversations</b><br>
Yi-Lin Tuan, Alon Albalak, Wenda Xu, <u>Michael Saxon</u>, Connor Pryor, Lise Getoor, William Yang Wang<br>
<i><b>ACL 2023 Findings</b></i> <br>
<a href="https://arxiv.org/abs/2212.10515">arXiv:2212.10515</a> <a href="https://arxiv.org/pdf/2212.10515">[pdf]</a></p>



<p style="padding-bottom: 10pt;"><b style="font-size:13pt;"> Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings</b><br>
Daniel Rose*, Vaishnavi Himakunthala*, Andy Ouyang*, Ryan He*, Alex Mei, Yujie Lu, <u>Michael Saxon</u>, Chinmay Sonar, Diba Mirza, William Yang Wang<br>
<i>Preprint</i> <br>
<a href="https://arxiv.org/abs/2305.02317">arXiv:2305.02317</a> <a href="https://arxiv.org/pdf/2305.02317">[pdf]</a></p>

<p style="padding-bottom: 10pt;"><b style="font-size:13pt;"> Users are the North Star for AI Transparency</b><br>
<u>Michael Saxon*</u>, Alex Mei*, Shiyu Chang, Zachary C Lipton, William Yang Wang<br>
<i>Preprint</i> <br>
<a href="https://arxiv.org/abs/2303.05500">arXiv:2303.05500</a> <a href="https://arxiv.org/pdf/2303.05500">[pdf]</a></p>
  

<p style="padding-bottom: 10pt;"><b style="font-size:13pt;">PECO: Examining Single Sentence Label Leakage in Natural Language Inference Datasets through Progressive Evaluation of Cluster Outliers</b><br>
<u>Michael Saxon</u>, Xinyi Wang, Wenda Xu, William Yang Wang<br>
<i><b>EACL 2023</b></i> <br>
<a href="https://arxiv.org/abs/2112.09237">arXiv:2112.09237</a> <a href="https://arxiv.org/pdf/2112.09237">[pdf]</a></p>



<p style="padding-bottom: 10pt;"><b style="font-size:13pt;"> WikiWhy: Answering and Explaining Cause-and-Effect Questions</b><br>
Matthew Ho, Aditya Sharma, Justin Chang, <u>Michael Saxon</u>, Sharon Levy, Yujie Lu, William Yang Wang<br>
<i><b>ICLR 2023 Oral</b></i> <br>
<a href="https://arxiv.org/abs/2210.12152">arXiv:2210.12152</a> <a href="https://arxiv.org/pdf/2210.12152">[pdf]</a></p>


<p style="padding-bottom: 10pt;"><b style="font-size:13pt;"> Causal Balancing for Domain Generalization</b><br>
Xinyi Wang, <u>Michael Saxon</u>, Jiachen Li, Hongyang Zhang, Kun Zhang, William Yang Wang<br>
<i><b>ICLR 2023</b></i> <br>
<a href="https://arxiv.org/abs/2206.05263">arXiv:2206.05263</a> <a href="https://arxiv.org/pdf/2206.05263">[pdf]</a></p>



<h4>2022</h4>



<p style="padding-bottom: 10pt;"><b style="font-size:13pt;"> Not All Errors are Equal: Learning Text Generation Metrics using Stratified Error Synthesis</b><br>
Wenda Xu, Yi-lin Tuan, Yujie Lu, <u>Michael Saxon</u>, Lei Li, William Yang Wang<br>
<i><b>EMNLP Findings 2022</b></i> <br>
<a href="https://arxiv.org/abs/2210.05035">arXiv:2210.05035</a> <a href="https://arxiv.org/pdf/2210.05035">[pdf]</a></p>


<p style="padding-bottom: 10pt;"><b style="font-size:13pt;"> Self-Supervised Knowledge Assimilation for Expert-Layman Text Style Transfer</b><br>
Wenda Xu, <u>Michael Saxon</u>, Misha Sra, William Yang Wang<br>
<i><b>AAAI 2022</b></i> <br>
<a href="https://arxiv.org/abs/2110.02950">arXiv:2110.02950</a> <a href="https://arxiv.org/pdf/2110.02950">[pdf]</a></p>

<h4>2021</h4>

<p style="padding-bottom: 10pt;"><b style="font-size:13pt;">Counterfactual Maximum Likelihood Estimation for Training Deep Networks</b><br>
Xinyi Wang, Wenhu Chen, <u>Michael Saxon</u>, William Yang Wang<br>
<i><b>NeurIPS 2021</b></i> <br>
<a href="https://arxiv.org/abs/2106.03831">arXiv:2106.03831</a> <a href="https://arxiv.org/pdf/2106.03831">[pdf]</a></p>

<p style="padding-bottom: 10pt;"><b style="font-size:13pt;">Modeling Disclosive Transparency in NLP Application Descriptions</b><br>
<u>Michael Saxon</u>, Sharon Levy, Xinyi Wang, Alon Albalak, William Yang Wang<br>
<i><b>EMNLP 2021 Oral</b></i> <br>
<a href="https://arxiv.org/abs/2101.00433">arXiv:2101.00433</a> <a href="https://arxiv.org/pdf/2101.00433.pdf">[pdf]</a></p>

<p style="padding-bottom: 10pt;"><b style="font-size:13pt;">End-to-End Spoken Language Understanding for Generalized Voice Assistants</b><br>
<u>Michael Saxon</u>, Samridhi Choudhary, Joseph P. McKenna, Athanasios Mouchtaris<br>
<i>Interspeech 2021</i> <br>
<a href="https://arxiv.org/abs/2106.09009">arXiv:2106.09009</a> <a href="https://arxiv.org/pdf/2106.09009">[pdf]</a></p>

<p style="padding-bottom: 10pt;"><b style="font-size:13pt;"> Investigating Conspiracy Theories in Text Generation</b><br>
Sharon Levy, <u>Michael Saxon</u>, William Yang Wang<br>
<i>ACL Findings 2021</i> <br>
<a href="https://arxiv.org/abs/2101.00379">arXiv:2101.00379</a> <a href="https://arxiv.org/pdf/2101.00379.pdf">[pdf]</a></p>

<h4>2020</h4>
<p style="padding-bottom: 10pt;"><b style="font-size:13pt;">Robust Estimation of Hypernasality in Dysarthria with Acoustic Model Likelihood Features</b><br>
<u>Michael Saxon</u>, Ayush Tripathi, Yishan Jiao,  Julie Liss, Visar Berisha<br>
<i>IEEE Transactions on Audio, Speech, and Language Processing (2020)</i> <br>
<a href="https://ieeexplore.ieee.org/abstract/document/9162481">[abs<font size="1pt"> (IEEE)</font>]</a> <a href="https://arxiv.org/abs/1911.11360">arXiv:1911.11360</a> <a href="https://arxiv.org/pdf/1911.11360.pdf">[pdf]</a></p>

<p style="padding-bottom: 10pt;"><b style="font-size:13pt;">Semantic Complexity in End-to-End Spoken Language Understanding</b><br>
<u>Michael Saxon</u>*, Joseph P. McKenna*, Samridhi Choudhary*, Grant Strimel, Athanasios Mouchtaris<br>
<i>Interspeech 2020</i><br>
<a href="https://www.isca-speech.org/archive/Interspeech_2020/abstracts/2929.html">[abs<font size="1pt"> (ISCA)</font>]</a> <a href="https://arxiv.org/abs/2008.02858">arXiv:2008.02858</a> <a href="https://www.isca-speech.org/archive/Interspeech_2020/pdfs/2929.pdf">[pdf]</a>
</p>

<p ><b style="font-size:13pt;">UncommonVoice: A Crowdsourced Dataset of Dysphonic Speech</b><br>
Meredith Moore, Piyush Papreja, <u>Michael Saxon</u>, Visar Berisha, Sethuraman Panchanathan<br>
<i>Interspeech 2020</i><br>
<a href="https://www.isca-speech.org/archive/Interspeech_2020/abstracts/3093.html">[abs<font size="1pt"> (ISCA)</font>]</a> <a href="https://www.isca-speech.org/archive/Interspeech_2020/pdfs/3093.pdf">[pdf]</a>
</p>


<h4>2019</h4>

<p style="padding-bottom: 10pt;"><b style="font-size:13pt;">Say what? A dataset for exploring the error patterns that two ASR engines make</b><br>
Meredith Moore, <u>Michael Saxon</u>, Hemanth Venkateswara, Visar Berisha, Sethuraman Panchanathan<br>
<i>Interspeech 2019</i><br>
<a href="https://www.isca-speech.org/archive/Interspeech_2019/abstracts/3096.html">[abs<font size="1pt"> (ISCA)</font>]</a> <a href="https://www.isca-speech.org/archive/Interspeech_2019/pdfs/3096.pdf">[pdf]</a>

</p>

<p ><b style="font-size:13pt;">Objective Measures of Plosive Nasalization in Hypernasal Speech</b><br>
<u>Michael Saxon</u>, Julie Liss, Visar Berisha<br>
<i>IEEE ICASSP 2019</i><br>
<a href="https://ieeexplore.ieee.org/abstract/document/8682339">[pdf<font size="1pt"> (IEEE)</font>]</a>
<a href="https://www.researchgate.net/publication/332790878_Objective_Measures_of_Plosive_Nasalization_in_Hypernasal_Speech">
  [pdf<font size="1pt"> (ResearchGate)</font>]</a>
</p>
<h4>2016</h4>
<p ><b style="font-size:13pt;">2D Grating Pitch Mapping of a through Silicon Via (TSV) and Solder
Ball Interconnect Region Using Laser Diffraction</b><br>
Todd Houghton, <u>Michael Saxon</u>, Zeming Song, Hoa Nguyen, Hanqing Jiang, Hongbin Yu<br>
<i>IEEE Electronic Components and Technology Conference (ECTC) 2016</i><br>
<b class="tomato">Best Student Interactive Paper Award!</b> <a href="https://ieeexplore.ieee.org/document/7545732">[pdf]</a>
</p>

<div style="height: 50px; width: 100%; text-align: center;">
<div style="display: inline-block; width: 30%; margin-top:25px; border-top: 1px solid black;"></div>
</div>



<h3 >Workshop Presentations</h3><br>

<h4>2023</h4>
<p><b style="font-size:12pt;"> Data Augmentation for Diverse Voice Conversion in Noisy Environments</b><br>
Avani Tanna <u>Michael Saxon</u>, Amr El Abaddi, William Yang Wang<br>
<i>Interspeech 2023 Show and Tell</i> <br>
<a href="https://arxiv.org/abs/2305.10684">[abs]</a></p>


<p style="padding-bottom: 10pt;"><b style="font-size:13pt;"> Disparities in Text-to-Image Model Concept Possession Across Languages</b><br>
<u>Michael Saxon</u>, William Yang Wang<br>
<i><b>FAccT 2023 Oral</b> (Non-archival)</i> <br>
<a href="https://openreview.net/forum?id=5H2m3tCEaQ">OpenReview:5H2m3tCEaQ</a> <a href="https://openreview.net/pdf?id=5H2m3tCEaQ">[pdf]</a> <a href="coco-crola/">[demo]</a></p>


<h4>2022</h4>
<p><b style="font-size:12pt;"> Automated Cheating Feature Semantic Identification for NLI Datasets </b><br>
<u>Michael Saxon</u>, Xinyi Wang, Wenda Xu, William Yang Wang<br>
<i>SoCal NLP 2022</i> <br>


<h4>2021</h4>
<p><b style="font-size:12pt;"> Modeling Disclosive Transparency with GPT-2</b><br>
<u>Michael Saxon</u>, Sharon Levy, Xinyi Wang, Alon Albalak, William Yang Wang<br>
<i>SoCal NLP 2021</i> <br>
<a href="https://docs.google.com/presentation/d/1pxJiJcjPg5brrlT_Kudw-sbFB7OTj0Fty9A7b7XWP18/">[poster]</a></p>

<h4>2020</h4>
<p><b style="font-size:12pt;"> A new model for objective estimation of hypernasality from dysarthric  speech</b><br>
<u>Michael Saxon</u>, Julie Liss, Visar Berisha<br>
<i>Workshop  on  Signal  Analytics  for  Motor  Speech  (SAMS),  Motor  Speech Conference 2020</i> <br>
<a href="doc/motor_speech_poster.pdf">[poster]</a></p>

<h4>2019</h4>
<p><b style="font-size:12pt;"> Word Pair Convolutional Model for Happy Moment Classification</b><br>
<u>Michael Saxon</u>*, Samarth Bhandari*, Lewis Ruskin, Gabrielle Honda<br>
<i>Workshop on Affective Content Analysis, AAAI 2019</i> <br>
<b class="tomato">CL-Aff Shared Task Runner Up!</b> <a href="http://ceur-ws.org/Vol-2328/4_paper_1.pdf">[pdf]</a>
</p>

<h4>2018</h4>

<p><b style="font-size:12pt;"> Chat-Box: Proposing a Mood Analyzer for Individuals with Social Interaction Disabilities</b><br>
Bineeta Gupta, <u>Michael Saxon</u>, Troy McDaniel, Sethuraman Panchanathan<br>
<i>International Conference on Human-Computer Interaction (HCII) Student Abstracts, 2018</i>
</p>


<div style="height: 50px; width: 100%; text-align: center;">
  <div style="display: inline-block; width: 30%; margin-top:25px; border-top: 1px solid black;"></div>
</div>

<h3 >Datasets</h3><br>
<h4>2019</h4>
ASU Pedestrian LiDAR Dataset&mdash;<a href="https://asulidarset.github.io">web link</a>

<div style="height: 50px; width: 100%; text-align: center;">
  <div style="display: inline-block; width: 30%; margin-top:25px; border-top: 1px solid black;"></div>
</div>



<div align="center"><i>Updated June 2023</i> &mdash; <a href="https://scholar.google.com/citations?user=pAlwjdgAAAAJ">Google Scholar</a></div>


</div>

<!--div style = "position:fixed;bottom: 15px;max-width:inherit;"-->


<footer style="margin-top:25pt; border-top: 1px dotted #676767; padding-top:10pt;"">
  <ul class="icons">
    <li><a href="https://www.semanticscholar.org/author/Michael-Stephen-Saxon/48227633" ><img class="filtercolor" src="img/ico/svg/semantic-scholar.svg"></a></li>
    <li><a href="https://scholar.google.com/citations?user=pAlwjdgAAAAJ&hl=en" ><img class="filtercolor" src="img/ico/svg/google-scholar.svg"></a></li>
    <li><a href="https://www.researchgate.net/profile/Michael_Saxon"><img class="filtercolor" src="img/ico/svg/researchgate.svg"></a></li>
    <li><a href="mailto:saxon@ucsb.edu"><img class="filtercolor" src="img/ico/svg/envelope.svg"></a></li>
    <li><a href="https://github.com/michaelsaxon"><img class="filtercolor" src="img/ico/svg/github-alt.svg"></a></li>
    <li><a href="https://www.youtube.com/@mssaxonUCSB"><img class="filtercolor" src="img/ico/svg/youtube.svg"></a></li>
    <li><a href="https://www.linkedin.com/in/mssaxon/"><img class="filtercolor" src="img/ico/svg/linkedin-in.svg"></a></li>
    <li><a href="https://bsky.app/profile/saxon.me" ><img class="filtercolor" src="img/ico/svg/cloud.svg"></a></li>
    <li><a rel="me" href="https://sigmoid.social/@saxon"><img class="filtercolor" src="img/ico/svg/mastodon.svg"></a></li>
    <li><a href="https://twitter.com/m2saxon" ><img class="filtercolor" src="img/ico/svg/twitter.svg"></a></li>
  
    </ul>
  
    <div class="worldmap"><script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=IuxqtNT-Q6MDtRyPajTC07_66TRmeCIPbVD4z2v4M_U&co=474747&cmn=547bfc'></script></div>


    <div style="max-width: 800px;   margin-right: auto; margin-left: auto;">
	    <p style="font-size:10pt; text-align: center">Core webpage incrementally scratchbuilt by me. Feel free to steal my source from <a href="https://github.com/michaelsaxon/michaelsaxon.github.io">GitHub</a>. Blog functionality made using <a href="https://getpelican.com/">Pelican</a>.</p>
    </div>

  <div style="width: 90pt; height: 25pt; background-color: #ddd; font-size: 9pt; border: 1pt solid black; margin-right: auto; margin-left: auto;
    background-image: url(https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Mozilla_Firefox_logo_2004.svg/133px-Mozilla_Firefox_logo_2004.svg.png);
    background-size: 27pt; background-repeat: no-repeat; padding-left:30pt; margin-bottom: 10pt;">
    Designed for <b><a href="https://www.mozilla.org/en-US/firefox/new/" style="color:#e27f2e;">Mozilla Firefox</a></b> on a <b style="color: #0060df;">real PC!</b>
  </div>

  </footer>


</body>
