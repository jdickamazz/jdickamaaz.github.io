<html>
<head>
<link rel="stylesheet" href="style.css">

<link href="https://fonts.googleapis.com/css?family=Merriweather|Oswald|Ubuntu+Mono" rel="stylesheet">
<title>Michael Saxon</title>
</head>
<body class="pgh">


  <div class="pageextl">

    <div class="header"><h1>MICHAEL SAXON</h1></div>



  <div class="page">
    <div class="contentl">
    <div class="menucontainer">
    <ul class="menu">
    <li><a href="index.html">About</a></li>
    <li><a class="active">Projects</a></li>
    <li><a href="research.html">Research</a></li>
    <!--<li><a href="fun.html">Fun</a></li>-->
      <li><a href="doc/cv_saxon.pdf">CV</a></li>
    </ul>
    </div>
    <img style='border-radius:50%;padding-right:20px;padding-bottom:20px;margin-top:20px;margin-left:20px;' src='img/me.png' width="150px" >
    <h3 >Michael Saxon</h3>
    <h3 >Ph.D. Student</h3>
    <h3 >UCSB NLP Group</h3>
    <ul class="icons">
    <li><a href="https://twitter.com/m2saxon" ><img src="img/ico/twitter.png"></a></li>
    <li><a href="https://www.researchgate.net/profile/Michael_Saxon"><img src="img/ico/researchgate.png"></a></li>
    <li><a href="https://www.linkedin.com/in/mssaxon/"><img src="img/ico/linkedin.png"></a></li>
    <li><a href="https://github.com/michaelsaxon"><img src="img/ico/github.png"></a></li>
    <li><a href="mailto:saxon@ucsb.edu"><img src="img/ico/email.png"></a></li>

    </ul>


  </div>
  </div>
  </div>


  <div class="pageextr">
  <div class="header">&nbsp;</div>

  <div class="page">
  <div class="contentr">


 <div align="center"><i>Updated January 26, 2019</i></div>

<h3>Bioinspired Deep Speech Processing and Synthesis</h3>
<i>2019 &mdash; present</i>
<p>My master's thesis project involving adapting neuromuscular modelling to drive better deep speech synthesis and processing.</p>

<h3>Affective Computing</h3>
<i>2018 &mdash; present</i>
<p>Created novel Word Pair Convolutional Model for classification of speaker agency and sociality of a self-description of happy moments for the CL-Aff shared task that achieved runner-up highest classification accuracy on the test set, and over 91% accuracy on cross validation evaluation.</p>
<p>Assisting in user study on the impact of audio/facial expression entrainment and conflict in emotion identification for visually impaired participants recieving haptic facial expression representations.</p>

 <h3>Principled LiDAR Processing</h3>
 <i>2017 &mdash; present</i>
 <p>Assisting in the collection of a pedestrian crowd "millions of LiDAR frames" dataset to facilitate a "predict next <i>n</i> LiDAR frames given previous <i>m</i>" task, and developing neural network architectures that can process the data.</p>
<p>Evaluated the performance of low-cost 16-segment solid state LiDAR units from Velodyne within an integrated video/distance frame paradigm, work in review for SPIE Journal.</p>

<h3>Disordered Speech Characterization</h3>
<i>2017 &mdash; 2018</i>
<p>Created ASR-based objective measures of hypernasality in speech leveraging common nasal/plosive co-located "cognates" for use in larger nasality classification systems that are disorder-agnostic. Work under review for ICASSP 2019</p>
<p>Aided in the integration of multiple objective measures including an acoustic feature and Goodness of Pronunciation for disorder-agnositc nasalit y classification. Work will be submitted to IEEE SPS.</p>

<h3>Strain Measurement Apparatus Control System</h3>
<i>2014 &mdash; 2015</i>
<p>Created integrated control and measurement system for sub micron-scale semiconductor optical strain measurement in LabVIEW.</p>

</div>

</div>
</div>
</body>
