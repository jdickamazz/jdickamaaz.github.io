<html>
<head>
<link rel="stylesheet" href="style.css">

<link href="https://fonts.googleapis.com/css?family=PT+Serif|Merriweather|Oswald|Ubuntu+Mono" rel="stylesheet">
<title>Michael Saxon - About</title>



<script src="resize.js">
</script>

<script>
  var txts = ["Hi, I'm Michael!", "初めまして、マイケルです！", "¡Hola, me llamo Michael!"]
  //var styles = ["italic", "normal", "italic"]
  //var variant = ["small-caps", "normal", "normal"]
  var counter = 1;
  function nameswap() {
    var doc = document.getElementById('nameintro')
    doc.innerHTML = txts[counter%3];
    //doc.fontStyle = styles[counter%3];
    //doc.fontVariant = variant[counter%3];
    counter++;
  }
</script>

<!--tomato-->

</head>
<!--body class="phx" onload="resizeleft()" onresize="resizeleft()"-->
<body>




  <!--div class="header"><h1>&nbsp;</h1></div-->


<header style="border-top:2px solid black; border-bottom: 1px dotted #676767; position:relative; min-height: 60px; overflow:hidden;">
  <!--div class="menucontainer"-->
  <div class="page">
  <h2 style="margin-top:6pt;float:left;"><a class="active" href="/">Michael Saxon</a></h2>
  <ul class="menu" style="margin-top:10pt;">
  <!--li><a href="projects.html">Projects</a></li-->
  <!--li><a href="/">About</a></li-->
  <li><a href="research">Publications</a></li>
  <!--li><a href="fun">Fun</a></li-->
    <li><a href="doc/cv_saxon.pdf">CV</a></li>
    <li><a href="blog/">Blog</a></li>
  </ul>
</div>
</header>



<div class="page" id="rightcontent" style="padding-top:15pt; overflow: hidden;">

  <!--/div-->
  <div style="max-width: 200px; float: left; text-align: center;">
  <!--img style='border-radius:50%;padding-right:20px;padding-bottom:20px;margin-top:20px;margin-left:20px;' src='img/me.png' width="150px" -->
  <img style='margin-right:20px;margin-bottom:20px;margin-top:6pt;margin-left:20px; border:1px solid #676767;padding:1px;' src='img/michael.jpg' width="150px" >
  <!--p style="text-align:center">Ph.D. Student, CS<br>
  UC Santa Barbara</p-->
  
</div>



<!--div class="header">&nbsp;</div-->

<div style="float:left; max-width: 600px;">
<!--h3 id="nameintro" onclick="nameswap()">Hi, I'm Michael!</h3-->
<p>
  I study generative AI artifacts like LLMs and text-to-image models.
  I'm particularly interested in making <b>meaningful evaluations of hard-to-measure new capabilities</b> in these artifacts.
  I think ethical issues in GenAI are both important to address and motivate interesting new technical challenges.
</p>
<p>
  Lately I've been thinking a lot about <b>automated metrics for text-to-image systems</b>. Unlike in the text domain, in continuous domains, characterizing things like "knowledge" in outputs by comparing to references is a challenge.
  My recent work <a href="https://aclanthology.org/2023.acl-long.266/">"CoCo-CroLa"</a> was a start in assessing multilingual knowledge for T2Is.
</p>


<!--p>In 2020 I completed my MS in Computer Engineering at Arizona State University, with research activities centered around speech processing, natural language processing, and deep learning methods for low-resourced populations with neurological disorders, and affective computing.</p-->
<!--In particular, I am interested in goal-based natural language generation, and assessing the “quality” of datasets. I want to improve our theoretical understanding of how aspects of dataset distribution and model assumptions drive generalization performance, and produce tools that can analyze data for unseen correlations, hidden confounders, and the like using empirical methods. I am most interested in applying these techniques to the learning of generalized natural language representations with an eye for their use in generating coherent, goal-oriented text.  Long term my aim is to work in the space of maximizing societal benefits and minimizing societal harms of natural language understanding.</p-->
<!--h3>Coursework</h3>
<p>My coursework choices have been selected to prepare me for this career, focusing on signal theory, signal processing, numerical methods, and AI, including <span class="mns">EEE404</span> <i>Real Time Digital Signal Processing</i>, <span class="mns">CSE310</span> <i>Algorithms and Data Structures</i>,
<span class="mns">MAT442</span> <i>Advanced Linear Algebra</i>, <span class="mns">EEE508</span> <i>Digital Image and Video Processing and Compression</i>, and <span class="mns">MAT421</span><i> Applied Computational Methods</i> to name a few.</p>
<p>In the Spring 2019 semester I will be taking <span class="mns">EEE554</span> <i>Random Signal Theory</i> and <span class="mns">EEE598</span> <i>Deep Learning for Media Processing and Understanding</i>, among other required electives.-->
</div>

<!--div style="max-width: 800px; float:left; background-color: #f5f5f5; padding: 10pt; margin: 5pt; border: 2pt solid rgb(147, 54, 37);">

<p><b class="tomato">
  I am looking for a Summer 2024 research internship! If you're looking for PhD interns to work on: </p>
  <ul>
    <li>Novel evaluations for generative AI</li>
    <li>Ethics in generative AI</li>
    <li>Multilinguality in text-to-image systems</li>
    <li>Building better text-to-image systems</li>
    <li>Something else?</li>
  </ul>
<p>
Then please reach out to my email: <emph><a href="mailto:saxon@ucsb.edu">saxon@ucsb.edu</a></emph>, thanks!</b>
</p>
</div>

<div style="max-width: 800px; float:right;"-->

<h4>Soon...</h4>
<p>Intern, <a href="https://www.amd.com/en/corporate/research.html">AMD Research, Open GenAI</a> (2024)</p>


<h4>Current</h4>
<p>PhD student, <a href="http://nlp.cs.ucsb.edu/">NLP Lab</a>, <a href="https://cs.ucsb.edu/">Computer Science</a>, <a href="https://www.ucsb.edu/">UC Santa Barbara</a> (2020&ndash;)<br> 
  Advised by <a href="https://sites.cs.ucsb.edu/~william/">William Yang Wang</a><br>
  Recipient, <a href="https://www.nsfgrfp.org/">NSF Graduate Research Fellowship</a> (2020)</p>

  <h4>Previously</h4>
<p>
  Intern, <a href="https://ai.facebook.com/">Meta AI (Cognitive AI/Conversational AI Research)</a> (2022)<br>
  Intern, <a href="https://www.amazon.science/publications">Amazon Alexa Web-based QA</a> (2021)<br>
  Intern, <a href="https://www.amazon.science/working-at-amazon/alexa-how-do-you-know-everything">Amazon Alexa Hybrid Science</a> (2019, 2020)<br>
  <br>
  MS <a href="https://cen.engineering.asu.edu/">Computer Engineering</a>, <a href="https://www.asu.edu/">Arizona State University</a> (2018&ndash;2020)<br>
  Advised by <a href="https://www.public.asu.edu/~visar/index.html">Visar Berisha</a> &amp; <a href="https://cubic.asu.edu/people">Sethuraman Panchanathan</a><br>
  <br>
  BSE <a href="https://ecee.engineering.asu.edu/">Electrical Engineering</a>,  <a href="https://www.asu.edu/">Arizona State University</a> (2014&ndash;2018)<br>
</p>


  <!--div style="height: 50px; width: 100%; text-align: center;">
    <div style="display: inline-block; width: 30%; margin-top:25px; border-top: 1px solid black;"></div>
    </div-->
    
<h4>News</h3>
<div style="height: 30em; width: auto; overflow: auto; padding-right: 0.5em; border-top: 2px solid #EAEEEA;"> 
<!-- Template
<p><b>date</b> Text <a href="">[link]</a></p>
-->

<p><b>5/4/2024</b> Had a great week visiting UMBC, Georgetown, UMD, and Johns Hopkins to present my work on rigorous measurement for text-to-image models. Check out the talk recording! <a href="https://www.youtube.com/watch?v=j0s0NB0b6wo">[YouTube]</a></p>

<p><b>4/8/2024</b> We were suprised to find that fancy VLM-based text-to-image faithfulness metrics don't actually outperform simple correlation-based ones using our new meta-evaluation T2IScoreScore! Check out our <a href="https://t2iscorescore.github.io/">interactive leaderboard</a>! <a href="https://arxiv.org/abs/2404.04251">[arXiv:2404.04251]</a></p>

<p><b>3/18/2024</b> Excited about our work diving deeper on characterizing failure cases in translation for text-to-image model testing! <a href="https://arxiv.org/abs/2403.11092">[arXiv:2403.11092]</a></p>

<p><b>12/10/2023</b> Wanrong presented our (mostly Xinyi's) work analyzing how in-context learning works for LLMs at NeurIPS 2023! Check out the paper: <a href="https://arxiv.org/abs/2301.11916/">[arXiv:2301.11916]</a></p>

<p><b>11/16/2023</b> Gave an invited talk on my recent work on assessing and improving multilingual knowledge and capabilities in T2I models at USC ISI! Video link: <a href="https://www.youtube.com/watch?v=nlu57ZSKbi0">[YouTube]</a></p>

<p><b>11/3/2023</b> Our dataset/paper proposing the task of "video infilling and prediction" for assessing reasoning capabilities of VLMs has been accepted to EMNLP! Link: <a href="https://arxiv.org/abs/2305.13903/">[arXiv:2305.13903]</a></p>

<p><b>8/6/2023</b> Our survey paper on self-correcting and automated correction methods for LLM workflows, "Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies" is up on arXiv! Link: <a href="https://arxiv.org/abs/2308.03188/">[arXiv:2308.03188]</a></p>

<p><b>7/13/2023</b> Presented <b>CoCo-CroLa</b> in the paper "Multilingual Conceptual Coverage in Text-to-Image Models" at ACL 2023! See the benchmark demo <a href="coco-crola/">[demo link]</a> and paper in ACL Anthology: <a href="https://aclanthology.org/2023.acl-long.266/">[ACL Anthology]</a></p>

<p><b>6/20/2023</b> Gave a talk at FAccT 2023 on <b>CoCo-CroLa</b> and our initial findings of interesting cross-lingual biases. Watch the talk! <a href="https://www.youtube.com/watch?v=tBYJFLaM71U">[YouTube]</a></p>

<p><b>5/8/2023</b> Presenting at ICLR 2023 was a blast! Check out the new dataset we presented in an oral, <b>WikiWhy</b>: <a href="https://arxiv.org/abs/arXiv:2210.12152">[arXiv:2210.12152]</a></p>

<p><b>3/9/2023</b> Check out me and Alex's position paper, "Users are the North Star for AI Transparency," written in collaboration with our advisor William, and profs Shiyu Chang and Zack Lipton! You'll probably like it more than the IJCAI reviewers did 😉 Preprint: <a href="https://arxiv.org/abs/arXiv:2303.05500">[arXiv:2303.05500]</a></p>

<p><b>1/23/2023</b> 2 of my papers were accepted to ICLR 2023 and one to EACL 2023! In particular I'm happy to share that <b class="tomato">WikiWhy</b>, a new benchmark for analyzing reasoning in LMs using QA got accepted as an oral presentation! Super proud of my undergrad group to get such an honor at ICLR for their first paper! Preprint here: <a href="https://arxiv.org/abs/arXiv:2210.12152">[arXiv:2210.12152]</a></p>

<p><b>12/20/2022</b> Check out my preprint "Multilingual Conceptual Coverage in Text-to-Image Models" on OpenReview! We quantify the degree to which T2I models including DALL-E and StableDiffusion contain representations of ~200 tangible concepts across EN, ES, DE, ZH, JA, HE, and ID. Preprint here: <a href="https://openreview.net/forum?id=5H2m3tCEaQ">[OpenReview:5H2m3tCEaQ]</a> <b>Demo available here: <a href="coco-crola/">[demo link]</a></b></p>

<p><b>11/18/2022</b> The 2022 Southern California NLP Symposium (SoCalNLP22) was a massive success! Co-chairing the program committee and participating in event organization was a great privilege and it was wonderful meeting everybody. Please check out our full event livestream <a href="https://www.youtube.com/watch?v=hwXA7x5KoCo">[YouTube Link]</a> and some event photos <a href="https://twitter.com/m2saxon/status/1594144831047016450">[Twitter:@m2saxon]</a> <a href="https://twitter.com/ucsbNLP/status/1594152788757344257">[Twitter:@ucsbNLP]</a>!</p>

<p><b>10/24/2022</b> Our general-purpose text-reference comparison metric that simulates human preferences for translation and summarization, <b class="tomato">SEScore</b>, is now available on <a href="https://huggingface.co/spaces/xu1998hz/sescore">HuggingFace spaces</a>!</b> Preprint here: <a href="https://arxiv.org/abs/arXiv:2210.05035">[arXiv:2210.05035]</a></p>

<p><b>10/12/2022</b> Our work "Not All Errors are Equal: Learning Text Generation Metrics using Stratified Error Synthesis" will appear in Findings of EMNLP 2022! Preprint here: <a href="https://arxiv.org/abs/2210.05035">[arXiv:2210.05035]</a></p>

<p><b>10/12/2022</b> Check out the latest preprint of my work "PECO: Examining Single Sentence Label Leakage in Natural Language Inference Datasets through Progressive Evaluation of Cluster Outliers" on arXiv! We demonstrated automated detection of spurious, annotator-driven correlations that lead to cheating features in NLI. Preprint here: <a href="https://arxiv.org/abs/2112.09237">[arXiv:2112.09237]</a></p>


<p><b>6/6/2022</b> Excited to start my 2022 AI Research Scientist Internship at Meta in Menlo Park!</p>


<p><b>12/3/2021</b> Our work "Self-Supervised Knowledge Assimilation for Expert-Layman Text Style Transfer" will appear at <b class="tomato">AAAI 2022</b>!</b> Preprint here: <a href="https://arxiv.org/abs/2110.02950">[arXiv:2110.02950]</a></p>

<p><b>11/8/2021</b> Had a great time presenting our <b class="tomato">Disclosive Transparency</b> work at <b class="tomato">EMNLP 2021</b>!</b> Our work was even highlighted in an <a href="https://www.innovation-nation.it/how-can-nlp-help-to-shape-reality-on-language-models-stereotypes-and-biases-mitigation-at-360/">EMNLP overview article</a>! Oral presentation prerecording:  <a href="https://www.youtube.com/watch?v=3fvcEdgI57I">[YouTube]</a></p>

<p><b>10/1/2021</b> Our work "Counterfactual Maximum Likelihood Estimation for Training Deep Networks" will appear at <b class="tomato">NeurIPS 2021</b>!</b> Preprint here: <a href="https://arxiv.org/abs/2106.03831">[arXiv:2106.03831]</a></p>

<p><b>9/23/2021</b> Our work "Modeling Disclosive Transparency in NLP Application Descriptions" will appear at <b class="tomato">EMNLP 2021</b> as an <b>oral presentation!</b> Preprint here: <a href="https://arxiv.org/abs/2101.00433">[arXiv:2101.00433]</a></p>

<p><b>9/13/2021</b> I was profiled on the <b class="tomato">Amazon Science Blog</b> about my experience doing multiple applied science internships with the company! Article here: <a href="https://www.amazon.science/working-at-amazon/alexa-how-do-you-know-everything">[amazon.science]</a></p>
</div>
<!--div style = "position:fixed;bottom: 15px;max-width:inherit;"-->



<!--div id="attrib" style="display:none;"><p style="font-size:8pt;">GitHub icon made by <a href="https://www.flaticon.com/authors/dave-gandy" title="Dave Gandy">Dave Gandy</a>
  from <a href="https://www.flaticon.com/" title="Flaticon"> www.flaticon.com</a> Twitter icon sourced from <a href="https://www.iconsdb.com/black-icons/twitter-icon.html">iconsdb.com</a>
  under CC0 1.0. ResearchGate and LinkedIn icons sourced from <a href="https://www.wtamu.edu/academics/college-agriculture-natural-sciences/department-life-earth-environmental-sciences/faculty/naruki-hiranuma.html">
    Dr. Naruki Hiranuma's faculty web page.</a></p></div-->
  </div>
</div>


<footer style="margin-top:25pt; border-top: 1px dotted #676767; padding-top:10pt;"">
  <ul class="icons">
    <li><a href="https://www.semanticscholar.org/author/Michael-Stephen-Saxon/48227633" ><img class="filtercolor" src="img/ico/svg/semantic-scholar.svg"></a></li>
    <li><a href="https://scholar.google.com/citations?user=pAlwjdgAAAAJ&hl=en" ><img class="filtercolor" src="img/ico/svg/google-scholar.svg"></a></li>
    <li><a href="https://www.researchgate.net/profile/Michael_Saxon"><img class="filtercolor" src="img/ico/svg/researchgate.svg"></a></li>
    <li><a href="mailto:saxon@ucsb.edu"><img class="filtercolor" src="img/ico/svg/envelope.svg"></a></li>
    <li><a href="https://github.com/michaelsaxon"><img class="filtercolor" src="img/ico/svg/github-alt.svg"></a></li>
    <li><a href="https://www.youtube.com/@mssaxonUCSB"><img class="filtercolor" src="img/ico/svg/youtube.svg"></a></li>
    <li><a href="https://www.linkedin.com/in/mssaxon/"><img class="filtercolor" src="img/ico/svg/linkedin-in.svg"></a></li>
    <li><a href="https://bsky.app/profile/saxon.me" ><img class="filtercolor" src="img/ico/svg/cloud.svg"></a></li>
    <li><a rel="me" href="https://sigmoid.social/@saxon"><img class="filtercolor" src="img/ico/svg/mastodon.svg"></a></li>
    <li><a href="https://twitter.com/m2saxon" ><img class="filtercolor" src="img/ico/svg/twitter.svg"></a></li>
  
    </ul>

    <div class="worldmap"><script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=IuxqtNT-Q6MDtRyPajTC07_66TRmeCIPbVD4z2v4M_U&co=474747&cmn=547bfc'></script></div>


    <div style="max-width: 800px;   margin-right: auto; margin-left: auto;">
	    <p style="font-size:10pt; text-align: center">Core webpage incrementally scratchbuilt by me. Feel free to steal my source from <a href="https://github.com/michaelsaxon/michaelsaxon.github.io">GitHub</a>. Blog functionality made using <a href="https://getpelican.com/">Pelican</a>.</p>
    </div>

  <div style="width: 90pt; height: 25pt; background-color: #ddd; font-size: 9pt; border: 1pt solid black; margin-right: auto; margin-left: auto;
    background-image: url(https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Mozilla_Firefox_logo_2004.svg/133px-Mozilla_Firefox_logo_2004.svg.png);
    background-size: 27pt; background-repeat: no-repeat; padding-left:30pt; margin-bottom: 10pt;">
    Designed for <b><a href="https://www.mozilla.org/en-US/firefox/new/" style="color:#e27f2e;">Mozilla Firefox</a></b> on a <b style="color: #0060df;">real PC!</b>
  </div>

  </footer>
  


</body>
